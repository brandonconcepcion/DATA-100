{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Variables**\n",
    "\n",
    "**Population parameter**: A number that describes something about the population \n",
    "\n",
    "**Sample statistic**: An estimate of the number computed on a sample\n",
    "\n",
    "### **17.1 Random Variables and Distribution**\n",
    "* A random variable is a *function* from the outome of a random event to a number \n",
    "* It is *random* since our sample was drawn at random; it is *variable* because its exact value depends on how this random sample came out \n",
    "\n",
    "Here are some examples: \n",
    "\n",
    "#### **17.1.1 Tossing a coin**\n",
    "* Let's define a fair coin toss \n",
    "* A far coin lands on heads $H$ or tails $T$, each with probability $0.5$. With these possible outcomes, we can define a random variable $X$ as: \n",
    "\n",
    "$$X = \\begin{cases} \n",
    "1, & \\text{if the coin lands heads} \\\\\n",
    "0, & \\text{if the coin lands tails}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Distributions**\n",
    "\n",
    "To define any random variable $X$, we need to be able to specify 2 things: \n",
    "1) **Possible values**: the set of values the random variable can take on \n",
    "2) **Probabilities**: the set of probabilities describing how the total probability of $100\\%$ is split over the possible values\n",
    "\n",
    "If $X$ is discrete (has a finite number of possible values), the probability that a random variable $X$ takes on the value $x$ is given by $P(X = x)$ and probabilities must sum to $1$ \n",
    "\n",
    "$$ \\sum_{\\text{all x}} P(X = x) = 1$$\n",
    "\n",
    "Consider the example:\n",
    "\n",
    "$$X = \\begin{cases} \n",
    "0, & P(X = x) = \\frac{1}{2}\\\\\n",
    "1, & P(X = x) = \\frac{1}{2}\n",
    "\\end{cases}$$\n",
    "\n",
    "The **distribution** of a random vaiable $X$ describe how the total probability of $100\\%$ is split across all possible values of $X$, fully defining a random variable \n",
    "\n",
    "The distribution of a discrete random variable can also be represented using a histogram. If the variable is **continuous**, meaning it can take on infinitely many values, then the histogram is smooth: \n",
    "\n",
    "<img src=\"https://ds100.org/course-notes/probability_1/images/discrete_continuous.png\" alt=\"Image Alt Text\" width=\"600\" height=\"220\">\n",
    "\n",
    "We often don't know the (true) distribution and inseatd compute an empirical distribution\n",
    "\n",
    "Probabilities are also areas\n",
    "* For discrete random variables, the area of the *red* bars represents the probability $X$ falls within those values \n",
    "* For continuous random variables, the *red area* under the curve represents the probabiility that $Y$ falls within those values \n",
    "\n",
    "<img src=\"https://ds100.org/course-notes/probability_1/images/probability_areas.png\" alt=\"Image Alt Text\" width=\"600\" height=\"270\">\n",
    "\n",
    "Summing up the areas under this curve should give us $1$\n",
    "\n",
    "Here is what a **probability distribution table** looks like\n",
    "\n",
    "<img src=\"https://ds100.org/course-notes/probability_1/images/distribution.png\" alt=\"Image Alt Text\" width=\"600\" height=\"240\">\n",
    "\n",
    "The common distributions are listed bellow: \n",
    "1) Bernoulli($p$): If $X$ ~ Bernoulli($p$), then $X$ takes on a value 1 with probability $p$, and $0$ with probability $1-p$. Bernoulli random variables are also termed the “indicator” random variables.\n",
    "\n",
    "2) Binomial($n$,$p$): If $X$~ Binomial($n$,$p$), then $X$ counts the number of $1$ s in $n$ independent Bernoulli($p$) trials.\n",
    "\n",
    "3) Categorical ($p_1, ... p_k$) of values: The probability of each value is $1$ / (number of possible values).\n",
    "\n",
    "4) Uniform on the unit interval $(0, 1)$: The density is flat at $1$ on $(0, 1)$ and $0$ elsewhere. We won’t get into what density means as much here, but intuitively, this is saying that there’s an equally likely chance of getting any value on the interval $(0, 1)$.\n",
    "\n",
    "5) Normal($\\mu$, $\\sigma ^2$): The probability density is specified by $\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}}$. This bell-shaped distribution comes up fairly often in data, in part due to the Central Limit Theorem you saw back in Data 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Expectation and Variance**\n",
    "\n",
    "**Expectation** of a random variable $X$ is the **weighted average** of the values of $X$, where the weights are the probabilities of each value occurring. \n",
    "\n",
    "1) Apply the weights one *sample* at a time: \n",
    "\n",
    "$$E[X] = \\sum_{\\text{all possible x}} x P(X = x)$$\n",
    "* The expectation is a *number*, not a random variable \n",
    "\n",
    "* Expectation is a generalization of the average, and it has the same units as the random variable \n",
    "\n",
    "* Also noted as the center of gravity of the probability distribution histogram, meaning if we simulate the variable many times, it is the long-run average of the simulated values \n",
    "\n",
    "**Variance** of a random variable is a measue of its chance error. \n",
    "* Variance asks: how far does $X$ typically vary from its average value, just by chance?\n",
    "\n",
    "$$\\text{Var}(X) = E[X^2] - (E[X])^2$$\n",
    "\n",
    "The units of variance are in the squared units of $X$. To get it back on the right scaled, we can define the notion of standard deviation \n",
    "\n",
    "$$\\text{SD}(X) = \\sqrt{\\text{Var}(X)}$$\n",
    "\n",
    "Calculating $E[X^2]$ is as follows: \n",
    "\n",
    "$${E}[X^2] = \\sum_{x} x^2 P(X = x)$$\n",
    "\n",
    "Here is an illustration of everything we know so far:\n",
    "\n",
    "<img src=\"https://ds100.org/course-notes/probability_1/images/exp_var.png\" alt=\"Image Alt Text\" width=\"600\" height=\"320\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Properties of Expectation**\n",
    "\n",
    "1) **Linearity of expectation**. The expectation of the linear transformation $aX + b$ where $a$ and $b$ are constants, is: \n",
    "\n",
    "$$\\mathbb{E}[aX+b] = aE[\\mathbb{X}] + b$$\n",
    "\n",
    "2) Expectation is also linear in *sums* of random variables \n",
    "\n",
    "$$\\mathbb{E}[X+Y] = \\mathbb{E}[X] + \\mathbb{E}[Y]$$\n",
    "\n",
    "\n",
    "### **Properties of Variance**\n",
    "\n",
    "Unlike expectation, variance is *non-linear*. The variance of the linear transformation \n",
    "\n",
    "$$ \\text{Var}(aX + b) = a^2 \\text{Var} (X) $$\n",
    "\n",
    "Subsequently, \n",
    "\n",
    "\n",
    "$$ \\text{SD}(aX + b) = |a| \\text{SD} (X) $$\n",
    "\n",
    "* Shifting the distribution by $b$ *does not* impact the *spread* of the distribution. Thus, $\\text{Var}(aX+b) = \\text{Var}(aX)$\n",
    "\n",
    "* Scaling the distribution by $a$ *does* impact the spread of the distribution \n",
    "\n",
    "<img src=\"https://ds100.org/course-notes/probability_1/images/transformation.png\" alt=\"Image Alt Text\" width=\"600\" height=\"220\">\n",
    "\n",
    "Another property of the sum of variances, is that this sum is affected by the (in)dependence of the random variables \n",
    "\n",
    "$$\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{cov}(X,Y)$$\n",
    "\n",
    "$$\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) \\qquad \\text{if } X, Y \\text{ independent}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Properties of Variance**\n",
    "\n",
    "We define **covariance** of two random variables as the expected product of deviations from its expectation: \n",
    "* More generally, it's a generalization of variance to variance \n",
    "\n",
    "$$\\text{Cov}(X, Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])]$$\n",
    "\n",
    "Using this, we can also use our notion of the **correlation coefficient**\n",
    "\n",
    "$$r(X, Y) = \\mathbb{E}\\left[\\left(\\frac{X-\\mathbb{E}[X]}{\\text{SD}(X)}\\right)\\left(\\frac{Y-\\mathbb{E}[Y]}{\\text{SD}(Y)}\\right)\\right] = \\frac{\\text{Cov}(X, Y)}{\\text{SD}(X)\\text{SD}(Y)}$$\n",
    "\n",
    "If $X$ and $Y$ are independent, then $\\text{Cov}(X,Y) = 0$ and $r(X,y) = 0$\n",
    "* This is not the same around, two variables $X$ and $Y$ may have $\\text{Cov}(X,Y) = 0$ and $r(X,y) = 0$ but not be independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Equal vs. Identically Distributed**\n",
    "\n",
    "Suppose that we have two random variables $X$ and $Y$\n",
    "* $X$ and $Y$ are **equal** if $X(s) = Y(s)$ for every samples $s$. Regardless of the exact sample drawn, $X$ is always equal to $Y$\n",
    "    * Same thing as saying for each outcome in the probability space $X$ and $Y$ will produce the same value\n",
    "    * Specifically, $X = Y$ with probability $1$ \n",
    "\n",
    "* $X$ and $Y$ are **identically distributed** if the distribution of $X$ is equal to the distribution of $Y$. \n",
    "    * $X$ and $Y$ take on the same set of possible values, and each one of these possible values is taken with the same probability \n",
    "    * Imagine rolling two dice: the probability distribution for each is identical\n",
    "\n",
    "* $X$ and $Y$ are **independent and identically distributed (i.i.d)** if \n",
    "    * The variables are identically distributed \n",
    "    * Knowing the outcome of one variable does not influence our belief of the outcome of the other  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
